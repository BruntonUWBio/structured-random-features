{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ac1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd\n",
    "from os.path import abspath, join\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.load_dataset import load_kmnist\n",
    "from src.models.networks import V1_mnist_RFNet, classical_RFNet\n",
    "from src.models.utils import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9991192-616c-4f7c-a90a-9461b1e392b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c88b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpandey/anaconda3/envs/random_features/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_batch_size, train_percentage = 64, 0.01\n",
    "train_loader, val_loader, test_loader = load_kmnist(train_batch_size, train_percentage)\n",
    "\n",
    "# training params\n",
    "num_epochs = 10\n",
    "step_size, gamma = 5, 0.1 # lr scheduler\n",
    "num_trials = 50\n",
    "log_interval = 100\n",
    "num_neurons = sorted(set(np.logspace(0, 3.5, 50).astype('int')))\n",
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59756014",
   "metadata": {},
   "source": [
    "### V1 RFNet with optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3135c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/44 [02:55<2:05:40, 175.37s/it]"
     ]
    }
   ],
   "source": [
    "s, f, c = 5.34, 1.965, None\n",
    "lr = 0.0031485838088746586\n",
    "\n",
    "test_v1 = {'hidden_size': [], 'mean': [], 'std': []}\n",
    "for hidden_size in tqdm(num_neurons):\n",
    "    accuracy = []\n",
    "    for trial in range(num_trials):\n",
    "        model = V1_mnist_RFNet(hidden_size, s, f, c).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            _ = train(log_interval, device, model, train_loader, optimizer, epoch, loss_fn, verbose=False)\n",
    "            scheduler.step()\n",
    "        accuracy.append(test(model, device, test_loader, verbose=False))\n",
    "        \n",
    "    test_v1['hidden_size'].append(hidden_size)\n",
    "    test_v1['mean'].append(np.mean(accuracy))\n",
    "    test_v1['std'].append(np.std(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e04f0",
   "metadata": {},
   "source": [
    "### Classical RFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5248863",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (1, 28, 28)\n",
    "lr = 0.01922083004518646\n",
    "\n",
    "test_classical = {'hidden_size': [], 'mean': [], 'std': []} \n",
    "for hidden_size in tqdm(num_neurons):\n",
    "    accuracy = []\n",
    "    for trial in range(num_trials):\n",
    "        model = classical_RFNet(inp_size, hidden_size).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            _ = train(log_interval, device, model, train_loader, optimizer, epoch, loss_fn, verbose=False)\n",
    "            scheduler.step()\n",
    "        accuracy.append(test(model, device, test_loader, verbose=False))\n",
    "\n",
    "    test_classical['hidden_size'].append(hidden_size)\n",
    "    test_classical['mean'].append(np.mean(accuracy))\n",
    "    test_classical['std'].append(np.std(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba99b82",
   "metadata": {},
   "source": [
    "### V1 RFNet with incompatible parameters $s=0.5$, $f=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95772fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s, f, c = 0.5, 0.5, None\n",
    "lr = 0.0031485838088746586\n",
    "\n",
    "test_incompatible = {'hidden_size': [], 'mean': [], 'std': []}\n",
    "for hidden_size in tqdm(num_neurons):\n",
    "    accuracy = []\n",
    "    for trial in range(num_trials):\n",
    "        model = V1_mnist_RFNet(hidden_size, s, f, c).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            _ = train(log_interval, device, model, train_loader, optimizer, epoch, loss_fn, verbose=False)\n",
    "            scheduler.step()\n",
    "        accuracy.append(test(model, device, test_loader, verbose=False))\n",
    "        \n",
    "    test_incompatible['hidden_size'].append(hidden_size)\n",
    "    test_incompatible['mean'].append(np.mean(accuracy))\n",
    "    test_incompatible['std'].append(np.std(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7746eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "test_classical = {'hidden_size': [], 'mean': [], 'std': []} \n",
    "test_incompatible = {'hidden_size': [], 'mean': [], 'std': []}\n",
    "test = {'v1': test_v1, 'classical': test_classical, 'incompatible': test_incompatible}\n",
    "data_dir = abspath(join(getcwd(), '../../'))\n",
    "with open(data_dir + '/models/results/kmnist_clf/kmnist_clf_s=%0.2f_f=%0.2f_fewshot_torch.pickle' % (s, f), 'wb') as handle:\n",
    "    pickle.dump(test, handle, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(test_v1['hidden_size'], test_v1['mean'])\n",
    "plt.plot(test_classical['hidden_size'], test_classical['mean'])\n",
    "plt.plot(test_incompatible['hidden_size'], test_incompatible['mean'])\n",
    "plt.xlim([0, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e994ddd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 10.733999999999998),\n",
       " (2, 10.3376),\n",
       " (3, 11.683000000000002),\n",
       " (4, 11.913400000000001),\n",
       " (5, 12.441200000000002),\n",
       " (6, 12.8752),\n",
       " (7, 13.2948),\n",
       " (8, 13.9174),\n",
       " (10, 15.0318),\n",
       " (11, 16.6122),\n",
       " (13, 17.998),\n",
       " (16, 19.477600000000002),\n",
       " (19, 21.809200000000004),\n",
       " (22, 23.952399999999997),\n",
       " (26, 26.952199999999998),\n",
       " (31, 29.332400000000003),\n",
       " (37, 32.281),\n",
       " (43, 34.942800000000005),\n",
       " (51, 37.3968),\n",
       " (61, 40.098800000000004),\n",
       " (71, 42.9318),\n",
       " (84, 44.24759999999999),\n",
       " (100, 47.1958),\n",
       " (117, 49.57019999999999),\n",
       " (138, 51.151399999999995),\n",
       " (163, 52.84960000000001),\n",
       " (193, 54.490199999999994),\n",
       " (227, 56.096599999999995),\n",
       " (268, 57.35560000000001),\n",
       " (316, 58.5168),\n",
       " (372, 59.386999999999986),\n",
       " (439, 60.1482),\n",
       " (517, 61.157399999999996),\n",
       " (610, 61.63539999999999),\n",
       " (719, 62.345600000000005),\n",
       " (848, 62.6916)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(test_v1['hidden_size'], test_v1['mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b347f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
