{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4a2bac1-37d7-4f8e-b7de-d2132cfd2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.data.load_dataset import load_mnist, load_kmnist\n",
    "from src.models.networks import V1_mnist_RFNet, classical_RFNet\n",
    "from src.models.utils import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "77ec6b2f-7b97-4eda-a370-9bcece703502",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bca9b5-6f22-4b90-982f-18143b8a22b9",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f784a581-1db4-47cc-9d60-4ec03ae8d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = load_mnist(128, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0c407870-e8d5-4b80-93ae-963e247b066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_epoch: 1 [0/60 (0%)]\tLoss: 76.416374\n",
      "\n",
      "Test set: Average loss: 72.421745. Accuracy: 6142/59940 (10.25%)\n",
      "\n",
      "Train_epoch: 2 [0/60 (0%)]\tLoss: 62.351219\n",
      "\n",
      "Test set: Average loss: 69.834061. Accuracy: 6213/59940 (10.37%)\n",
      "\n",
      "Train_epoch: 3 [0/60 (0%)]\tLoss: 46.042698\n",
      "\n",
      "Test set: Average loss: 67.277260. Accuracy: 6265/59940 (10.45%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 68.620743. Accuracy: 1014/10000 (10.14%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h, s, f, c = 100, 5, 2, None\n",
    "model = V1_mnist_RFNet(h, s, f, c).to(device)\n",
    "\n",
    "# hyperparams\n",
    "lr = 1E-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# train\n",
    "epochs = 5\n",
    "log_interval = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(log_interval, device, model, train_loader, optimizer, epoch, verbose=True)\n",
    "    val_accuracy = test(model, device, val_loader)\n",
    "# calculate and print test accuracy\n",
    "test_accuracy = test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce43b0c9-4dca-4879-905a-6825427c9d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_epoch: 1 [0/60 (0%)]\tLoss: 0.019425\n",
      "Train_epoch: 1 [50/60 (83%)]\tLoss: 0.041692\n",
      "\n",
      "Test set: Average loss: 1.747105. Accuracy: 33799/59940 (56.39%)\n",
      "\n",
      "Train_epoch: 2 [0/60 (0%)]\tLoss: 0.017553\n",
      "Train_epoch: 2 [50/60 (83%)]\tLoss: 0.012458\n",
      "\n",
      "Test set: Average loss: 2.020098. Accuracy: 33126/59940 (55.27%)\n",
      "\n",
      "Train_epoch: 3 [0/60 (0%)]\tLoss: 0.002029\n",
      "Train_epoch: 3 [50/60 (83%)]\tLoss: 0.052165\n",
      "\n",
      "Test set: Average loss: 2.324098. Accuracy: 32765/59940 (54.66%)\n",
      "\n",
      "Train_epoch: 4 [0/60 (0%)]\tLoss: 0.004036\n",
      "Train_epoch: 4 [50/60 (83%)]\tLoss: 0.016046\n",
      "\n",
      "Test set: Average loss: 2.192673. Accuracy: 33303/59940 (55.56%)\n",
      "\n",
      "Train_epoch: 5 [0/60 (0%)]\tLoss: 0.114517\n",
      "Train_epoch: 5 [50/60 (83%)]\tLoss: 0.002865\n",
      "\n",
      "Test set: Average loss: 2.145921. Accuracy: 33166/59940 (55.33%)\n",
      "\n",
      "Train_epoch: 6 [0/60 (0%)]\tLoss: 0.002516\n",
      "Train_epoch: 6 [50/60 (83%)]\tLoss: 0.002040\n",
      "\n",
      "Test set: Average loss: 2.434522. Accuracy: 31560/59940 (52.65%)\n",
      "\n",
      "Train_epoch: 7 [0/60 (0%)]\tLoss: 0.000541\n",
      "Train_epoch: 7 [50/60 (83%)]\tLoss: 0.002423\n",
      "\n",
      "Test set: Average loss: 2.562590. Accuracy: 31382/59940 (52.36%)\n",
      "\n",
      "Train_epoch: 8 [0/60 (0%)]\tLoss: 0.006410\n",
      "Train_epoch: 8 [50/60 (83%)]\tLoss: 0.000446\n",
      "\n",
      "Test set: Average loss: 2.410451. Accuracy: 32737/59940 (54.62%)\n",
      "\n",
      "Train_epoch: 9 [0/60 (0%)]\tLoss: 0.001139\n",
      "Train_epoch: 9 [50/60 (83%)]\tLoss: 0.000639\n",
      "\n",
      "Test set: Average loss: 2.314633. Accuracy: 33617/59940 (56.08%)\n",
      "\n",
      "Train_epoch: 10 [0/60 (0%)]\tLoss: 0.000818\n",
      "Train_epoch: 10 [50/60 (83%)]\tLoss: 0.001005\n",
      "\n",
      "Test set: Average loss: 2.271592. Accuracy: 33956/59940 (56.65%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.228732. Accuracy: 5772/10000 (57.72%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## classical network\n",
    "inp_size, hidden_size = (1, 28, 28), 100\n",
    "model = classical_RFNet(inp_size, hidden_size, seed=10).to(device)\n",
    "\n",
    "# optimizer\n",
    "lr = 1E-1\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# train\n",
    "epochs = 5\n",
    "log_interval = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(log_interval, device, model, train_loader, optimizer, epoch, verbose=True)\n",
    "    val_accuracy = test(model, device, val_loader)\n",
    "# calculate and print test accuracy\n",
    "test_accuracy = test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9519afa-0eff-43a9-bd82-c22a8c1e8593",
   "metadata": {},
   "source": [
    "### KMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "08b749d7-fae8-4354-bed5-662a782baed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = load_kmnist(128, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "658007d4-1d99-4aef-850f-bdbacc61c04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_epoch: 1 [0/54000 (0%)]\tLoss: 58.635796\n",
      "Train_epoch: 1 [640/54000 (1%)]\tLoss: 68.013962\n",
      "Train_epoch: 1 [1280/54000 (2%)]\tLoss: 60.708252\n",
      "Train_epoch: 1 [1920/54000 (4%)]\tLoss: 56.057079\n",
      "Train_epoch: 1 [2560/54000 (5%)]\tLoss: 53.962803\n",
      "Train_epoch: 1 [3200/54000 (6%)]\tLoss: 51.828499\n",
      "Train_epoch: 1 [3840/54000 (7%)]\tLoss: 50.861771\n",
      "Train_epoch: 1 [4480/54000 (8%)]\tLoss: 49.518036\n",
      "Train_epoch: 1 [5120/54000 (9%)]\tLoss: 47.843136\n",
      "Train_epoch: 1 [5760/54000 (11%)]\tLoss: 48.851124\n",
      "Train_epoch: 1 [6400/54000 (12%)]\tLoss: 46.666237\n",
      "Train_epoch: 1 [7040/54000 (13%)]\tLoss: 40.818386\n",
      "Train_epoch: 1 [7680/54000 (14%)]\tLoss: 42.839558\n",
      "Train_epoch: 1 [8320/54000 (15%)]\tLoss: 47.759418\n",
      "Train_epoch: 1 [8960/54000 (17%)]\tLoss: 44.923611\n",
      "Train_epoch: 1 [9600/54000 (18%)]\tLoss: 38.171677\n",
      "Train_epoch: 1 [10240/54000 (19%)]\tLoss: 43.106647\n",
      "Train_epoch: 1 [10880/54000 (20%)]\tLoss: 41.316811\n",
      "Train_epoch: 1 [11520/54000 (21%)]\tLoss: 33.943554\n",
      "Train_epoch: 1 [12160/54000 (23%)]\tLoss: 42.514233\n",
      "Train_epoch: 1 [12800/54000 (24%)]\tLoss: 32.038399\n",
      "Train_epoch: 1 [13440/54000 (25%)]\tLoss: 35.080467\n",
      "Train_epoch: 1 [14080/54000 (26%)]\tLoss: 37.900700\n",
      "Train_epoch: 1 [14720/54000 (27%)]\tLoss: 36.376205\n",
      "Train_epoch: 1 [15360/54000 (28%)]\tLoss: 34.665554\n",
      "Train_epoch: 1 [16000/54000 (30%)]\tLoss: 37.343914\n",
      "Train_epoch: 1 [16640/54000 (31%)]\tLoss: 34.985058\n",
      "Train_epoch: 1 [17280/54000 (32%)]\tLoss: 39.171406\n",
      "Train_epoch: 1 [17920/54000 (33%)]\tLoss: 40.125038\n",
      "Train_epoch: 1 [18560/54000 (34%)]\tLoss: 28.052782\n",
      "Train_epoch: 1 [19200/54000 (36%)]\tLoss: 28.060446\n",
      "Train_epoch: 1 [19840/54000 (37%)]\tLoss: 27.175777\n",
      "Train_epoch: 1 [20480/54000 (38%)]\tLoss: 33.117355\n",
      "Train_epoch: 1 [21120/54000 (39%)]\tLoss: 32.317097\n",
      "Train_epoch: 1 [21760/54000 (40%)]\tLoss: 28.343866\n",
      "Train_epoch: 1 [22400/54000 (41%)]\tLoss: 29.769829\n",
      "Train_epoch: 1 [23040/54000 (43%)]\tLoss: 31.133318\n",
      "Train_epoch: 1 [23680/54000 (44%)]\tLoss: 27.777782\n",
      "Train_epoch: 1 [24320/54000 (45%)]\tLoss: 27.579254\n",
      "Train_epoch: 1 [24960/54000 (46%)]\tLoss: 26.465446\n",
      "Train_epoch: 1 [25600/54000 (47%)]\tLoss: 24.157475\n",
      "Train_epoch: 1 [26240/54000 (49%)]\tLoss: 25.574030\n",
      "Train_epoch: 1 [26880/54000 (50%)]\tLoss: 29.527958\n",
      "Train_epoch: 1 [27520/54000 (51%)]\tLoss: 23.541790\n",
      "Train_epoch: 1 [28160/54000 (52%)]\tLoss: 23.479929\n",
      "Train_epoch: 1 [28800/54000 (53%)]\tLoss: 25.993933\n",
      "Train_epoch: 1 [29440/54000 (55%)]\tLoss: 25.552826\n",
      "Train_epoch: 1 [30080/54000 (56%)]\tLoss: 23.560839\n",
      "Train_epoch: 1 [30720/54000 (57%)]\tLoss: 25.891434\n",
      "Train_epoch: 1 [31360/54000 (58%)]\tLoss: 22.112440\n",
      "Train_epoch: 1 [32000/54000 (59%)]\tLoss: 24.859526\n",
      "Train_epoch: 1 [32640/54000 (60%)]\tLoss: 28.029345\n",
      "Train_epoch: 1 [33280/54000 (62%)]\tLoss: 20.296164\n",
      "Train_epoch: 1 [33920/54000 (63%)]\tLoss: 20.066366\n",
      "Train_epoch: 1 [34560/54000 (64%)]\tLoss: 18.515024\n",
      "Train_epoch: 1 [35200/54000 (65%)]\tLoss: 17.936663\n",
      "Train_epoch: 1 [35840/54000 (66%)]\tLoss: 16.755276\n",
      "Train_epoch: 1 [36480/54000 (68%)]\tLoss: 18.599640\n",
      "Train_epoch: 1 [37120/54000 (69%)]\tLoss: 19.785254\n",
      "Train_epoch: 1 [37760/54000 (70%)]\tLoss: 15.720044\n",
      "Train_epoch: 1 [38400/54000 (71%)]\tLoss: 18.606781\n",
      "Train_epoch: 1 [39040/54000 (72%)]\tLoss: 17.138763\n",
      "Train_epoch: 1 [39680/54000 (73%)]\tLoss: 16.887957\n",
      "Train_epoch: 1 [40320/54000 (75%)]\tLoss: 18.331274\n",
      "Train_epoch: 1 [40960/54000 (76%)]\tLoss: 19.949860\n",
      "Train_epoch: 1 [41600/54000 (77%)]\tLoss: 16.172646\n",
      "Train_epoch: 1 [42240/54000 (78%)]\tLoss: 18.137602\n",
      "Train_epoch: 1 [42880/54000 (79%)]\tLoss: 13.220997\n",
      "Train_epoch: 1 [43520/54000 (81%)]\tLoss: 17.003246\n",
      "Train_epoch: 1 [44160/54000 (82%)]\tLoss: 14.216195\n",
      "Train_epoch: 1 [44800/54000 (83%)]\tLoss: 14.136712\n",
      "Train_epoch: 1 [45440/54000 (84%)]\tLoss: 17.193020\n",
      "Train_epoch: 1 [46080/54000 (85%)]\tLoss: 16.536049\n",
      "Train_epoch: 1 [46720/54000 (86%)]\tLoss: 17.813353\n",
      "Train_epoch: 1 [47360/54000 (88%)]\tLoss: 16.342171\n",
      "Train_epoch: 1 [48000/54000 (89%)]\tLoss: 13.888067\n",
      "Train_epoch: 1 [48640/54000 (90%)]\tLoss: 14.625042\n",
      "Train_epoch: 1 [49280/54000 (91%)]\tLoss: 15.422870\n",
      "Train_epoch: 1 [49920/54000 (92%)]\tLoss: 14.020984\n",
      "Train_epoch: 1 [50560/54000 (94%)]\tLoss: 13.718115\n",
      "Train_epoch: 1 [51200/54000 (95%)]\tLoss: 13.523437\n",
      "Train_epoch: 1 [51840/54000 (96%)]\tLoss: 11.051891\n",
      "Train_epoch: 1 [52480/54000 (97%)]\tLoss: 14.441922\n",
      "Train_epoch: 1 [53120/54000 (98%)]\tLoss: 13.151730\n",
      "Train_epoch: 1 [53760/54000 (100%)]\tLoss: 12.393385\n",
      "\n",
      "Test set: Average loss: 12.889578. Accuracy: 2444/6000 (40.73%)\n",
      "\n",
      "Train_epoch: 2 [0/54000 (0%)]\tLoss: 14.211342\n",
      "Train_epoch: 2 [640/54000 (1%)]\tLoss: 12.207479\n",
      "Train_epoch: 2 [1280/54000 (2%)]\tLoss: 12.888970\n",
      "Train_epoch: 2 [1920/54000 (4%)]\tLoss: 11.119437\n",
      "Train_epoch: 2 [2560/54000 (5%)]\tLoss: 13.225474\n",
      "Train_epoch: 2 [3200/54000 (6%)]\tLoss: 12.051720\n",
      "Train_epoch: 2 [3840/54000 (7%)]\tLoss: 12.379628\n",
      "Train_epoch: 2 [4480/54000 (8%)]\tLoss: 12.036437\n",
      "Train_epoch: 2 [5120/54000 (9%)]\tLoss: 13.482152\n",
      "Train_epoch: 2 [5760/54000 (11%)]\tLoss: 10.735478\n",
      "Train_epoch: 2 [6400/54000 (12%)]\tLoss: 11.805452\n",
      "Train_epoch: 2 [7040/54000 (13%)]\tLoss: 11.707721\n",
      "Train_epoch: 2 [7680/54000 (14%)]\tLoss: 14.103759\n",
      "Train_epoch: 2 [8320/54000 (15%)]\tLoss: 12.956007\n",
      "Train_epoch: 2 [8960/54000 (17%)]\tLoss: 11.770608\n",
      "Train_epoch: 2 [9600/54000 (18%)]\tLoss: 14.018521\n",
      "Train_epoch: 2 [10240/54000 (19%)]\tLoss: 8.968958\n",
      "Train_epoch: 2 [10880/54000 (20%)]\tLoss: 10.497565\n",
      "Train_epoch: 2 [11520/54000 (21%)]\tLoss: 10.592293\n",
      "Train_epoch: 2 [12160/54000 (23%)]\tLoss: 10.551224\n",
      "Train_epoch: 2 [12800/54000 (24%)]\tLoss: 11.317572\n",
      "Train_epoch: 2 [13440/54000 (25%)]\tLoss: 11.456879\n",
      "Train_epoch: 2 [14080/54000 (26%)]\tLoss: 12.232642\n",
      "Train_epoch: 2 [14720/54000 (27%)]\tLoss: 10.908649\n",
      "Train_epoch: 2 [15360/54000 (28%)]\tLoss: 11.694900\n",
      "Train_epoch: 2 [16000/54000 (30%)]\tLoss: 10.140015\n",
      "Train_epoch: 2 [16640/54000 (31%)]\tLoss: 11.295928\n",
      "Train_epoch: 2 [17280/54000 (32%)]\tLoss: 7.745137\n",
      "Train_epoch: 2 [17920/54000 (33%)]\tLoss: 10.192084\n",
      "Train_epoch: 2 [18560/54000 (34%)]\tLoss: 9.348433\n",
      "Train_epoch: 2 [19200/54000 (36%)]\tLoss: 10.059495\n",
      "Train_epoch: 2 [19840/54000 (37%)]\tLoss: 10.101174\n",
      "Train_epoch: 2 [20480/54000 (38%)]\tLoss: 8.823177\n",
      "Train_epoch: 2 [21120/54000 (39%)]\tLoss: 9.225640\n",
      "Train_epoch: 2 [21760/54000 (40%)]\tLoss: 11.270524\n",
      "Train_epoch: 2 [22400/54000 (41%)]\tLoss: 10.988345\n",
      "Train_epoch: 2 [23040/54000 (43%)]\tLoss: 10.267046\n",
      "Train_epoch: 2 [23680/54000 (44%)]\tLoss: 9.417686\n",
      "Train_epoch: 2 [24320/54000 (45%)]\tLoss: 10.253069\n",
      "Train_epoch: 2 [24960/54000 (46%)]\tLoss: 8.456083\n",
      "Train_epoch: 2 [25600/54000 (47%)]\tLoss: 7.674455\n",
      "Train_epoch: 2 [26240/54000 (49%)]\tLoss: 8.414321\n",
      "Train_epoch: 2 [26880/54000 (50%)]\tLoss: 9.968984\n",
      "Train_epoch: 2 [27520/54000 (51%)]\tLoss: 10.216243\n",
      "Train_epoch: 2 [28160/54000 (52%)]\tLoss: 8.723848\n",
      "Train_epoch: 2 [28800/54000 (53%)]\tLoss: 10.483966\n",
      "Train_epoch: 2 [29440/54000 (55%)]\tLoss: 7.955471\n",
      "Train_epoch: 2 [30080/54000 (56%)]\tLoss: 7.854697\n",
      "Train_epoch: 2 [30720/54000 (57%)]\tLoss: 8.657841\n",
      "Train_epoch: 2 [31360/54000 (58%)]\tLoss: 6.190403\n",
      "Train_epoch: 2 [32000/54000 (59%)]\tLoss: 7.582305\n",
      "Train_epoch: 2 [32640/54000 (60%)]\tLoss: 11.508623\n",
      "Train_epoch: 2 [33280/54000 (62%)]\tLoss: 8.580699\n",
      "Train_epoch: 2 [33920/54000 (63%)]\tLoss: 8.763696\n",
      "Train_epoch: 2 [34560/54000 (64%)]\tLoss: 8.190344\n",
      "Train_epoch: 2 [35200/54000 (65%)]\tLoss: 10.632671\n",
      "Train_epoch: 2 [35840/54000 (66%)]\tLoss: 8.080705\n",
      "Train_epoch: 2 [36480/54000 (68%)]\tLoss: 8.303760\n",
      "Train_epoch: 2 [37120/54000 (69%)]\tLoss: 7.465271\n",
      "Train_epoch: 2 [37760/54000 (70%)]\tLoss: 7.698195\n",
      "Train_epoch: 2 [38400/54000 (71%)]\tLoss: 9.029832\n",
      "Train_epoch: 2 [39040/54000 (72%)]\tLoss: 8.654290\n",
      "Train_epoch: 2 [39680/54000 (73%)]\tLoss: 6.535524\n",
      "Train_epoch: 2 [40320/54000 (75%)]\tLoss: 6.859869\n",
      "Train_epoch: 2 [40960/54000 (76%)]\tLoss: 7.901702\n",
      "Train_epoch: 2 [41600/54000 (77%)]\tLoss: 7.911687\n",
      "Train_epoch: 2 [42240/54000 (78%)]\tLoss: 8.178580\n",
      "Train_epoch: 2 [42880/54000 (79%)]\tLoss: 8.235424\n",
      "Train_epoch: 2 [43520/54000 (81%)]\tLoss: 7.545907\n",
      "Train_epoch: 2 [44160/54000 (82%)]\tLoss: 5.254779\n",
      "Train_epoch: 2 [44800/54000 (83%)]\tLoss: 8.387837\n",
      "Train_epoch: 2 [45440/54000 (84%)]\tLoss: 5.800565\n",
      "Train_epoch: 2 [46080/54000 (85%)]\tLoss: 6.975804\n",
      "Train_epoch: 2 [46720/54000 (86%)]\tLoss: 8.280302\n",
      "Train_epoch: 2 [47360/54000 (88%)]\tLoss: 6.690245\n",
      "Train_epoch: 2 [48000/54000 (89%)]\tLoss: 7.232674\n",
      "Train_epoch: 2 [48640/54000 (90%)]\tLoss: 7.167495\n",
      "Train_epoch: 2 [49280/54000 (91%)]\tLoss: 8.617211\n",
      "Train_epoch: 2 [49920/54000 (92%)]\tLoss: 6.414572\n",
      "Train_epoch: 2 [50560/54000 (94%)]\tLoss: 6.791993\n",
      "Train_epoch: 2 [51200/54000 (95%)]\tLoss: 8.080241\n",
      "Train_epoch: 2 [51840/54000 (96%)]\tLoss: 5.972626\n",
      "Train_epoch: 2 [52480/54000 (97%)]\tLoss: 8.466464\n",
      "Train_epoch: 2 [53120/54000 (98%)]\tLoss: 5.875447\n",
      "Train_epoch: 2 [53760/54000 (100%)]\tLoss: 6.580250\n",
      "\n",
      "Test set: Average loss: 7.022928. Accuracy: 3544/6000 (59.07%)\n",
      "\n",
      "Train_epoch: 3 [0/54000 (0%)]\tLoss: 6.801407\n",
      "Train_epoch: 3 [640/54000 (1%)]\tLoss: 7.435958\n",
      "Train_epoch: 3 [1280/54000 (2%)]\tLoss: 8.936544\n",
      "Train_epoch: 3 [1920/54000 (4%)]\tLoss: 7.048231\n",
      "Train_epoch: 3 [2560/54000 (5%)]\tLoss: 8.367964\n",
      "Train_epoch: 3 [3200/54000 (6%)]\tLoss: 7.888903\n",
      "Train_epoch: 3 [3840/54000 (7%)]\tLoss: 8.027257\n",
      "Train_epoch: 3 [4480/54000 (8%)]\tLoss: 7.075174\n",
      "Train_epoch: 3 [5120/54000 (9%)]\tLoss: 7.202030\n",
      "Train_epoch: 3 [5760/54000 (11%)]\tLoss: 7.520204\n",
      "Train_epoch: 3 [6400/54000 (12%)]\tLoss: 5.301551\n",
      "Train_epoch: 3 [7040/54000 (13%)]\tLoss: 7.806732\n",
      "Train_epoch: 3 [7680/54000 (14%)]\tLoss: 5.156814\n",
      "Train_epoch: 3 [8320/54000 (15%)]\tLoss: 5.446721\n",
      "Train_epoch: 3 [8960/54000 (17%)]\tLoss: 7.582172\n",
      "Train_epoch: 3 [9600/54000 (18%)]\tLoss: 7.395352\n",
      "Train_epoch: 3 [10240/54000 (19%)]\tLoss: 6.294630\n",
      "Train_epoch: 3 [10880/54000 (20%)]\tLoss: 7.603657\n",
      "Train_epoch: 3 [11520/54000 (21%)]\tLoss: 5.952203\n",
      "Train_epoch: 3 [12160/54000 (23%)]\tLoss: 5.881988\n",
      "Train_epoch: 3 [12800/54000 (24%)]\tLoss: 5.499908\n",
      "Train_epoch: 3 [13440/54000 (25%)]\tLoss: 8.040226\n",
      "Train_epoch: 3 [14080/54000 (26%)]\tLoss: 8.293212\n",
      "Train_epoch: 3 [14720/54000 (27%)]\tLoss: 6.505636\n",
      "Train_epoch: 3 [15360/54000 (28%)]\tLoss: 7.771785\n",
      "Train_epoch: 3 [16000/54000 (30%)]\tLoss: 6.064516\n",
      "Train_epoch: 3 [16640/54000 (31%)]\tLoss: 4.781744\n",
      "Train_epoch: 3 [17280/54000 (32%)]\tLoss: 6.758521\n",
      "Train_epoch: 3 [17920/54000 (33%)]\tLoss: 6.886217\n",
      "Train_epoch: 3 [18560/54000 (34%)]\tLoss: 6.387506\n",
      "Train_epoch: 3 [19200/54000 (36%)]\tLoss: 7.322135\n",
      "Train_epoch: 3 [19840/54000 (37%)]\tLoss: 6.664897\n",
      "Train_epoch: 3 [20480/54000 (38%)]\tLoss: 4.462975\n",
      "Train_epoch: 3 [21120/54000 (39%)]\tLoss: 7.752576\n",
      "Train_epoch: 3 [21760/54000 (40%)]\tLoss: 5.316965\n",
      "Train_epoch: 3 [22400/54000 (41%)]\tLoss: 7.506333\n",
      "Train_epoch: 3 [23040/54000 (43%)]\tLoss: 6.644844\n",
      "Train_epoch: 3 [23680/54000 (44%)]\tLoss: 5.180577\n",
      "Train_epoch: 3 [24320/54000 (45%)]\tLoss: 8.703319\n",
      "Train_epoch: 3 [24960/54000 (46%)]\tLoss: 6.751441\n",
      "Train_epoch: 3 [25600/54000 (47%)]\tLoss: 6.106784\n",
      "Train_epoch: 3 [26240/54000 (49%)]\tLoss: 5.659011\n",
      "Train_epoch: 3 [26880/54000 (50%)]\tLoss: 6.791948\n",
      "Train_epoch: 3 [27520/54000 (51%)]\tLoss: 7.546397\n",
      "Train_epoch: 3 [28160/54000 (52%)]\tLoss: 5.007867\n",
      "Train_epoch: 3 [28800/54000 (53%)]\tLoss: 4.830809\n",
      "Train_epoch: 3 [29440/54000 (55%)]\tLoss: 6.618642\n",
      "Train_epoch: 3 [30080/54000 (56%)]\tLoss: 6.826352\n",
      "Train_epoch: 3 [30720/54000 (57%)]\tLoss: 5.412265\n",
      "Train_epoch: 3 [31360/54000 (58%)]\tLoss: 5.673042\n",
      "Train_epoch: 3 [32000/54000 (59%)]\tLoss: 6.043786\n",
      "Train_epoch: 3 [32640/54000 (60%)]\tLoss: 5.110891\n",
      "Train_epoch: 3 [33280/54000 (62%)]\tLoss: 3.846391\n",
      "Train_epoch: 3 [33920/54000 (63%)]\tLoss: 5.707697\n",
      "Train_epoch: 3 [34560/54000 (64%)]\tLoss: 4.445095\n",
      "Train_epoch: 3 [35200/54000 (65%)]\tLoss: 4.674038\n",
      "Train_epoch: 3 [35840/54000 (66%)]\tLoss: 7.880712\n",
      "Train_epoch: 3 [36480/54000 (68%)]\tLoss: 5.321327\n",
      "Train_epoch: 3 [37120/54000 (69%)]\tLoss: 3.650170\n",
      "Train_epoch: 3 [37760/54000 (70%)]\tLoss: 5.248582\n",
      "Train_epoch: 3 [38400/54000 (71%)]\tLoss: 3.878060\n",
      "Train_epoch: 3 [39040/54000 (72%)]\tLoss: 5.092030\n",
      "Train_epoch: 3 [39680/54000 (73%)]\tLoss: 6.366377\n",
      "Train_epoch: 3 [40320/54000 (75%)]\tLoss: 3.837568\n",
      "Train_epoch: 3 [40960/54000 (76%)]\tLoss: 4.593406\n",
      "Train_epoch: 3 [41600/54000 (77%)]\tLoss: 4.678353\n",
      "Train_epoch: 3 [42240/54000 (78%)]\tLoss: 4.672289\n",
      "Train_epoch: 3 [42880/54000 (79%)]\tLoss: 5.655645\n",
      "Train_epoch: 3 [43520/54000 (81%)]\tLoss: 5.030829\n",
      "Train_epoch: 3 [44160/54000 (82%)]\tLoss: 6.027080\n",
      "Train_epoch: 3 [44800/54000 (83%)]\tLoss: 6.073215\n",
      "Train_epoch: 3 [45440/54000 (84%)]\tLoss: 5.733389\n",
      "Train_epoch: 3 [46080/54000 (85%)]\tLoss: 4.557015\n",
      "Train_epoch: 3 [46720/54000 (86%)]\tLoss: 6.523640\n",
      "Train_epoch: 3 [47360/54000 (88%)]\tLoss: 4.241545\n",
      "Train_epoch: 3 [48000/54000 (89%)]\tLoss: 5.917907\n",
      "Train_epoch: 3 [48640/54000 (90%)]\tLoss: 5.075724\n",
      "Train_epoch: 3 [49280/54000 (91%)]\tLoss: 5.755806\n",
      "Train_epoch: 3 [49920/54000 (92%)]\tLoss: 3.482743\n",
      "Train_epoch: 3 [50560/54000 (94%)]\tLoss: 7.022581\n",
      "Train_epoch: 3 [51200/54000 (95%)]\tLoss: 5.789664\n",
      "Train_epoch: 3 [51840/54000 (96%)]\tLoss: 6.088186\n",
      "Train_epoch: 3 [52480/54000 (97%)]\tLoss: 3.883067\n",
      "Train_epoch: 3 [53120/54000 (98%)]\tLoss: 5.655677\n",
      "Train_epoch: 3 [53760/54000 (100%)]\tLoss: 5.056668\n",
      "\n",
      "Test set: Average loss: 5.095811. Accuracy: 4004/6000 (66.73%)\n",
      "\n",
      "Train_epoch: 4 [0/54000 (0%)]\tLoss: 4.514489\n",
      "Train_epoch: 4 [640/54000 (1%)]\tLoss: 6.943266\n",
      "Train_epoch: 4 [1280/54000 (2%)]\tLoss: 4.174417\n",
      "Train_epoch: 4 [1920/54000 (4%)]\tLoss: 6.693200\n",
      "Train_epoch: 4 [2560/54000 (5%)]\tLoss: 6.232249\n",
      "Train_epoch: 4 [3200/54000 (6%)]\tLoss: 4.950239\n",
      "Train_epoch: 4 [3840/54000 (7%)]\tLoss: 5.461442\n",
      "Train_epoch: 4 [4480/54000 (8%)]\tLoss: 5.823063\n",
      "Train_epoch: 4 [5120/54000 (9%)]\tLoss: 4.822070\n",
      "Train_epoch: 4 [5760/54000 (11%)]\tLoss: 2.736368\n",
      "Train_epoch: 4 [6400/54000 (12%)]\tLoss: 5.174506\n",
      "Train_epoch: 4 [7040/54000 (13%)]\tLoss: 5.093962\n",
      "Train_epoch: 4 [7680/54000 (14%)]\tLoss: 3.216915\n",
      "Train_epoch: 4 [8320/54000 (15%)]\tLoss: 4.677790\n",
      "Train_epoch: 4 [8960/54000 (17%)]\tLoss: 6.337779\n",
      "Train_epoch: 4 [9600/54000 (18%)]\tLoss: 4.450750\n",
      "Train_epoch: 4 [10240/54000 (19%)]\tLoss: 5.565938\n",
      "Train_epoch: 4 [10880/54000 (20%)]\tLoss: 5.200883\n",
      "Train_epoch: 4 [11520/54000 (21%)]\tLoss: 5.341032\n",
      "Train_epoch: 4 [12160/54000 (23%)]\tLoss: 6.440409\n",
      "Train_epoch: 4 [12800/54000 (24%)]\tLoss: 4.734626\n",
      "Train_epoch: 4 [13440/54000 (25%)]\tLoss: 3.632862\n",
      "Train_epoch: 4 [14080/54000 (26%)]\tLoss: 4.357130\n",
      "Train_epoch: 4 [14720/54000 (27%)]\tLoss: 2.783565\n",
      "Train_epoch: 4 [15360/54000 (28%)]\tLoss: 4.561319\n",
      "Train_epoch: 4 [16000/54000 (30%)]\tLoss: 4.150112\n",
      "Train_epoch: 4 [16640/54000 (31%)]\tLoss: 5.571811\n",
      "Train_epoch: 4 [17280/54000 (32%)]\tLoss: 6.137285\n",
      "Train_epoch: 4 [17920/54000 (33%)]\tLoss: 3.970851\n",
      "Train_epoch: 4 [18560/54000 (34%)]\tLoss: 5.723454\n",
      "Train_epoch: 4 [19200/54000 (36%)]\tLoss: 4.770218\n",
      "Train_epoch: 4 [19840/54000 (37%)]\tLoss: 4.426214\n",
      "Train_epoch: 4 [20480/54000 (38%)]\tLoss: 6.109726\n",
      "Train_epoch: 4 [21120/54000 (39%)]\tLoss: 4.033903\n",
      "Train_epoch: 4 [21760/54000 (40%)]\tLoss: 7.307107\n",
      "Train_epoch: 4 [22400/54000 (41%)]\tLoss: 4.484906\n",
      "Train_epoch: 4 [23040/54000 (43%)]\tLoss: 4.856395\n",
      "Train_epoch: 4 [23680/54000 (44%)]\tLoss: 2.901979\n",
      "Train_epoch: 4 [24320/54000 (45%)]\tLoss: 4.510523\n",
      "Train_epoch: 4 [24960/54000 (46%)]\tLoss: 3.894819\n",
      "Train_epoch: 4 [25600/54000 (47%)]\tLoss: 5.210036\n",
      "Train_epoch: 4 [26240/54000 (49%)]\tLoss: 3.651290\n",
      "Train_epoch: 4 [26880/54000 (50%)]\tLoss: 5.444491\n",
      "Train_epoch: 4 [27520/54000 (51%)]\tLoss: 4.670970\n",
      "Train_epoch: 4 [28160/54000 (52%)]\tLoss: 3.667710\n",
      "Train_epoch: 4 [28800/54000 (53%)]\tLoss: 4.275301\n",
      "Train_epoch: 4 [29440/54000 (55%)]\tLoss: 5.237160\n",
      "Train_epoch: 4 [30080/54000 (56%)]\tLoss: 3.026806\n",
      "Train_epoch: 4 [30720/54000 (57%)]\tLoss: 5.428218\n",
      "Train_epoch: 4 [31360/54000 (58%)]\tLoss: 3.476370\n",
      "Train_epoch: 4 [32000/54000 (59%)]\tLoss: 6.129232\n",
      "Train_epoch: 4 [32640/54000 (60%)]\tLoss: 4.800385\n",
      "Train_epoch: 4 [33280/54000 (62%)]\tLoss: 3.651351\n",
      "Train_epoch: 4 [33920/54000 (63%)]\tLoss: 3.294056\n",
      "Train_epoch: 4 [34560/54000 (64%)]\tLoss: 4.899285\n",
      "Train_epoch: 4 [35200/54000 (65%)]\tLoss: 4.131628\n",
      "Train_epoch: 4 [35840/54000 (66%)]\tLoss: 4.672226\n",
      "Train_epoch: 4 [36480/54000 (68%)]\tLoss: 4.074855\n",
      "Train_epoch: 4 [37120/54000 (69%)]\tLoss: 4.674886\n",
      "Train_epoch: 4 [37760/54000 (70%)]\tLoss: 3.295722\n",
      "Train_epoch: 4 [38400/54000 (71%)]\tLoss: 5.035065\n",
      "Train_epoch: 4 [39040/54000 (72%)]\tLoss: 2.726698\n",
      "Train_epoch: 4 [39680/54000 (73%)]\tLoss: 3.467239\n",
      "Train_epoch: 4 [40320/54000 (75%)]\tLoss: 4.078107\n",
      "Train_epoch: 4 [40960/54000 (76%)]\tLoss: 2.408278\n",
      "Train_epoch: 4 [41600/54000 (77%)]\tLoss: 3.814527\n",
      "Train_epoch: 4 [42240/54000 (78%)]\tLoss: 4.993176\n",
      "Train_epoch: 4 [42880/54000 (79%)]\tLoss: 3.725570\n",
      "Train_epoch: 4 [43520/54000 (81%)]\tLoss: 4.292960\n",
      "Train_epoch: 4 [44160/54000 (82%)]\tLoss: 4.161417\n",
      "Train_epoch: 4 [44800/54000 (83%)]\tLoss: 5.316437\n",
      "Train_epoch: 4 [45440/54000 (84%)]\tLoss: 4.200020\n",
      "Train_epoch: 4 [46080/54000 (85%)]\tLoss: 4.850419\n",
      "Train_epoch: 4 [46720/54000 (86%)]\tLoss: 4.385147\n",
      "Train_epoch: 4 [47360/54000 (88%)]\tLoss: 2.326337\n",
      "Train_epoch: 4 [48000/54000 (89%)]\tLoss: 3.688408\n",
      "Train_epoch: 4 [48640/54000 (90%)]\tLoss: 4.440927\n",
      "Train_epoch: 4 [49280/54000 (91%)]\tLoss: 3.794660\n",
      "Train_epoch: 4 [49920/54000 (92%)]\tLoss: 3.817879\n",
      "Train_epoch: 4 [50560/54000 (94%)]\tLoss: 3.133581\n",
      "Train_epoch: 4 [51200/54000 (95%)]\tLoss: 3.356025\n",
      "Train_epoch: 4 [51840/54000 (96%)]\tLoss: 2.913967\n",
      "Train_epoch: 4 [52480/54000 (97%)]\tLoss: 2.780684\n",
      "Train_epoch: 4 [53120/54000 (98%)]\tLoss: 3.480504\n",
      "Train_epoch: 4 [53760/54000 (100%)]\tLoss: 4.084984\n",
      "\n",
      "Test set: Average loss: 4.010584. Accuracy: 4222/6000 (70.37%)\n",
      "\n",
      "Train_epoch: 5 [0/54000 (0%)]\tLoss: 4.869121\n",
      "Train_epoch: 5 [640/54000 (1%)]\tLoss: 3.138654\n",
      "Train_epoch: 5 [1280/54000 (2%)]\tLoss: 4.103051\n",
      "Train_epoch: 5 [1920/54000 (4%)]\tLoss: 4.115925\n",
      "Train_epoch: 5 [2560/54000 (5%)]\tLoss: 3.258833\n",
      "Train_epoch: 5 [3200/54000 (6%)]\tLoss: 4.595155\n",
      "Train_epoch: 5 [3840/54000 (7%)]\tLoss: 5.131864\n",
      "Train_epoch: 5 [4480/54000 (8%)]\tLoss: 3.497455\n",
      "Train_epoch: 5 [5120/54000 (9%)]\tLoss: 4.248256\n",
      "Train_epoch: 5 [5760/54000 (11%)]\tLoss: 3.190927\n",
      "Train_epoch: 5 [6400/54000 (12%)]\tLoss: 3.692935\n",
      "Train_epoch: 5 [7040/54000 (13%)]\tLoss: 4.370613\n",
      "Train_epoch: 5 [7680/54000 (14%)]\tLoss: 3.798310\n",
      "Train_epoch: 5 [8320/54000 (15%)]\tLoss: 4.002932\n",
      "Train_epoch: 5 [8960/54000 (17%)]\tLoss: 3.625180\n",
      "Train_epoch: 5 [9600/54000 (18%)]\tLoss: 3.630111\n",
      "Train_epoch: 5 [10240/54000 (19%)]\tLoss: 2.295530\n",
      "Train_epoch: 5 [10880/54000 (20%)]\tLoss: 3.029003\n",
      "Train_epoch: 5 [11520/54000 (21%)]\tLoss: 4.138479\n",
      "Train_epoch: 5 [12160/54000 (23%)]\tLoss: 4.179539\n",
      "Train_epoch: 5 [12800/54000 (24%)]\tLoss: 4.879525\n",
      "Train_epoch: 5 [13440/54000 (25%)]\tLoss: 5.399005\n",
      "Train_epoch: 5 [14080/54000 (26%)]\tLoss: 4.802780\n",
      "Train_epoch: 5 [14720/54000 (27%)]\tLoss: 3.340062\n",
      "Train_epoch: 5 [15360/54000 (28%)]\tLoss: 3.392001\n",
      "Train_epoch: 5 [16000/54000 (30%)]\tLoss: 3.563321\n",
      "Train_epoch: 5 [16640/54000 (31%)]\tLoss: 4.285531\n",
      "Train_epoch: 5 [17280/54000 (32%)]\tLoss: 3.533099\n",
      "Train_epoch: 5 [17920/54000 (33%)]\tLoss: 3.202816\n",
      "Train_epoch: 5 [18560/54000 (34%)]\tLoss: 3.970415\n",
      "Train_epoch: 5 [19200/54000 (36%)]\tLoss: 2.990409\n",
      "Train_epoch: 5 [19840/54000 (37%)]\tLoss: 2.513159\n",
      "Train_epoch: 5 [20480/54000 (38%)]\tLoss: 4.114593\n",
      "Train_epoch: 5 [21120/54000 (39%)]\tLoss: 4.497054\n",
      "Train_epoch: 5 [21760/54000 (40%)]\tLoss: 2.903100\n",
      "Train_epoch: 5 [22400/54000 (41%)]\tLoss: 5.098611\n",
      "Train_epoch: 5 [23040/54000 (43%)]\tLoss: 2.963640\n",
      "Train_epoch: 5 [23680/54000 (44%)]\tLoss: 5.302889\n",
      "Train_epoch: 5 [24320/54000 (45%)]\tLoss: 4.461207\n",
      "Train_epoch: 5 [24960/54000 (46%)]\tLoss: 3.550183\n",
      "Train_epoch: 5 [25600/54000 (47%)]\tLoss: 5.492949\n",
      "Train_epoch: 5 [26240/54000 (49%)]\tLoss: 4.090463\n",
      "Train_epoch: 5 [26880/54000 (50%)]\tLoss: 3.469669\n",
      "Train_epoch: 5 [27520/54000 (51%)]\tLoss: 3.061351\n",
      "Train_epoch: 5 [28160/54000 (52%)]\tLoss: 4.030992\n",
      "Train_epoch: 5 [28800/54000 (53%)]\tLoss: 3.856998\n",
      "Train_epoch: 5 [29440/54000 (55%)]\tLoss: 3.603507\n",
      "Train_epoch: 5 [30080/54000 (56%)]\tLoss: 2.503155\n",
      "Train_epoch: 5 [30720/54000 (57%)]\tLoss: 2.471654\n",
      "Train_epoch: 5 [31360/54000 (58%)]\tLoss: 3.399647\n",
      "Train_epoch: 5 [32000/54000 (59%)]\tLoss: 3.034134\n",
      "Train_epoch: 5 [32640/54000 (60%)]\tLoss: 4.687878\n",
      "Train_epoch: 5 [33280/54000 (62%)]\tLoss: 5.199444\n",
      "Train_epoch: 5 [33920/54000 (63%)]\tLoss: 4.320539\n",
      "Train_epoch: 5 [34560/54000 (64%)]\tLoss: 3.053512\n",
      "Train_epoch: 5 [35200/54000 (65%)]\tLoss: 4.267889\n",
      "Train_epoch: 5 [35840/54000 (66%)]\tLoss: 3.602322\n",
      "Train_epoch: 5 [36480/54000 (68%)]\tLoss: 2.945979\n",
      "Train_epoch: 5 [37120/54000 (69%)]\tLoss: 3.079595\n",
      "Train_epoch: 5 [37760/54000 (70%)]\tLoss: 2.941795\n",
      "Train_epoch: 5 [38400/54000 (71%)]\tLoss: 2.872160\n",
      "Train_epoch: 5 [39040/54000 (72%)]\tLoss: 3.499199\n",
      "Train_epoch: 5 [39680/54000 (73%)]\tLoss: 2.555812\n",
      "Train_epoch: 5 [40320/54000 (75%)]\tLoss: 3.443104\n",
      "Train_epoch: 5 [40960/54000 (76%)]\tLoss: 2.308018\n",
      "Train_epoch: 5 [41600/54000 (77%)]\tLoss: 3.528312\n",
      "Train_epoch: 5 [42240/54000 (78%)]\tLoss: 3.578221\n",
      "Train_epoch: 5 [42880/54000 (79%)]\tLoss: 2.866498\n",
      "Train_epoch: 5 [43520/54000 (81%)]\tLoss: 2.372383\n",
      "Train_epoch: 5 [44160/54000 (82%)]\tLoss: 4.329666\n",
      "Train_epoch: 5 [44800/54000 (83%)]\tLoss: 2.979918\n",
      "Train_epoch: 5 [45440/54000 (84%)]\tLoss: 3.468064\n",
      "Train_epoch: 5 [46080/54000 (85%)]\tLoss: 2.600995\n",
      "Train_epoch: 5 [46720/54000 (86%)]\tLoss: 3.784869\n",
      "Train_epoch: 5 [47360/54000 (88%)]\tLoss: 4.012710\n",
      "Train_epoch: 5 [48000/54000 (89%)]\tLoss: 3.002111\n",
      "Train_epoch: 5 [48640/54000 (90%)]\tLoss: 2.055383\n",
      "Train_epoch: 5 [49280/54000 (91%)]\tLoss: 3.612816\n",
      "Train_epoch: 5 [49920/54000 (92%)]\tLoss: 3.327815\n",
      "Train_epoch: 5 [50560/54000 (94%)]\tLoss: 3.827327\n",
      "Train_epoch: 5 [51200/54000 (95%)]\tLoss: 4.527205\n",
      "Train_epoch: 5 [51840/54000 (96%)]\tLoss: 2.705891\n",
      "Train_epoch: 5 [52480/54000 (97%)]\tLoss: 2.674620\n",
      "Train_epoch: 5 [53120/54000 (98%)]\tLoss: 3.090965\n",
      "Train_epoch: 5 [53760/54000 (100%)]\tLoss: 3.715116\n",
      "\n",
      "Test set: Average loss: 3.259418. Accuracy: 4355/6000 (72.58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 5.553703. Accuracy: 5916/10000 (59.16%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h, s, f, c = 100, 5, 2, None\n",
    "model = V1_mnist_RFNet(h, s, f, c).to(device)\n",
    "\n",
    "# hyperparams\n",
    "lr = 1E-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# train\n",
    "epochs = 5\n",
    "log_interval = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(log_interval, device, model, train_loader, optimizer, epoch, verbose=True)\n",
    "    val_accuracy = test(model, device, val_loader)\n",
    "# calculate and print test accuracy\n",
    "test_accuracy = test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31abc33-52fb-4563-b5b0-26bc8acec095",
   "metadata": {},
   "outputs": [],
   "source": [
    "## classical network\n",
    "inp_size, hidden_size = (1, 28, 28), 100\n",
    "model = classical_RFNet(inp_size, hidden_size, seed=10).to(device)\n",
    "\n",
    "# optimizer\n",
    "lr = 1E-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# train\n",
    "epochs = 5\n",
    "log_interval = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(log_interval, device, model, train_loader, optimizer, epoch, verbose=True)\n",
    "    val_accuracy = test(model, device, val_loader)\n",
    "# calculate and print test accuracy\n",
    "test_accuracy = test(model, device, test_loader)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
