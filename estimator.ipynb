{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nonlinearities\n",
    "def relu(x, thrsh=0):\n",
    "    return np.maximum(x, thrsh)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Random features with SVM classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, width=500, weights='white noise', nonlinearity=relu, clf=None, weight_fun=None, clf_args={}, \n",
    "                 seed=20):\n",
    "        self.width=width\n",
    "        self.weights = weights\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.clf = clf\n",
    "        self.weight_fun = weight_fun\n",
    "        self.clf_args = clf_args\n",
    "        self.seed=seed\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # check params\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError('dimension mismatch')\n",
    "        n = X.shape[1]\n",
    "\n",
    "        if self.clf is None:\n",
    "            self.clf = LinearSVC(random_state=self.seed, tol=1e-4, max_iter=1000)\n",
    "        else:\n",
    "            self.clf = self.clf(**self.clf_args)\n",
    "        \n",
    "        if self.weight_fun is not None:\n",
    "            self.W_ = self.weight_fun(self.width, n)\n",
    "        else:\n",
    "            self.W_ = \\\n",
    "            random_feature_matrix(self.width, n, self.weights, self.seed)\n",
    "        H = self.nonlinearity(X @ self.W_)\n",
    "        \n",
    "        #fit classifier\n",
    "        self.clf.fit(H, y)\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        H = self.nonlinearity(X @ self.W_)\n",
    "        return H\n",
    "    \n",
    "    def predict(self, X):\n",
    "        H = self.nonlinearity(X @ self.W_)\n",
    "        return self.clf.predict(H)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        H = self.nonlinearity(X @ self.W_)\n",
    "        return self.clf.score(H, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(X, mu, sigma):\n",
    "    return np.exp(-np.abs(mu - X) ** 2/ (2 * sigma **2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_feature_matrix(M, N, weights='white noise', rand_seed=20):\n",
    "    ''' \n",
    "    Generate a size (M, N) random matrix from the specified distribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    M: number of rows\n",
    "    \n",
    "    N: number of columns\n",
    "    \n",
    "    weights: string or function, default 'gaussian.'\n",
    "    If 'unimodal', entries are gaussians with means ~ Unif(0, 1), and std. dev ~ Unif(0.1, N).\n",
    "    If 'white noise', entries are drawn ~ N(0, 1).\n",
    "    Or can be a function handle taking arguments (M, N)\n",
    "    '''\n",
    "    \n",
    "    from numpy.random import randn, uniform, seed\n",
    "    \n",
    "    seed(rand_seed)\n",
    "    if weights == 'unimodal':\n",
    "        mu = uniform(0, N, (M, 1))\n",
    "        sigma = uniform(0.1, N/4, (M, 1))\n",
    "        k = np.arange(0, N)\n",
    "        J = np.array([gaussian(k, m, s) for (m, s) in zip(mu, sigma)]) * np.random.randint(1, 20, (M, 1))\n",
    "\n",
    "    elif weights == 'white noise':\n",
    "        J = randn(M, N)\n",
    "    \n",
    "    else:\n",
    "        J = weights(M, N)\n",
    "    return J.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5379032258064517"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tests to check the estimator.py\n",
    "from data_fns import noisy_signal, data_matrix, butter_bandpass_filter\n",
    "\n",
    "f_s = 2000\n",
    "dur = 10\n",
    "f_sig = 40\n",
    "sig_dur = 0.05\n",
    "\n",
    "# neuron memory\n",
    "delta = 0.08\n",
    "N = int(delta * f_s)\n",
    "\n",
    "signal, label = noisy_signal(f_s=f_s, dur=dur, f_signal=f_sig, sig_dur=sig_dur)\n",
    "X, y = data_matrix(signal, label, N)\n",
    "clf = RFClassifier(width=30, weights='white noise', weight_fun=None)\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
